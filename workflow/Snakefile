include: "tools/Snakefile.smk"

report: "report/workflow.rst"

ruleorder:  load_GN > load_mSM > unify > svd > trial_selection > locaNMF > parcellate >  thresholding > feature_grouping > feature_calculation

###   Output accumulation rules   ###

#rule paper:
    #input:
        #Fig 2: Timeseries Activity, Spatial Activity Maps, Frames

        #Fig 3: Framewise Decoding, Comparison FEatures: Framewise, Phasewide, Mean (Temporal + Across Parcel), Conf Matrizes, Class Coefs, Across Time
        #expand([f"results/paper/{dataset_id}/{subset_id}/{'.'.join(aggr_conditions)}/perf_all.feats.parcels.pdf" for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids]),

        #Decoding performance over time across: parcellations, features
        #expand([f"results/paper/{dataset_id}/{subset_id}/{{feature}}/{'.'.join(aggr_conditions)}/performance_over_time_parcels.pdf" for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],  feature =  features), # (3a)
        #expand([f"results/paper/{dataset_id}/{subset_id}/{{parcellation}}/{'.'.join(aggr_conditions)}/performance_over_time_features.pdf" for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],  parcellation = parcellations), # (3b)

#rule subdivided_svd:

#rule brain_alignment:

rule parcellation: 
    input:
        #Result of parcellations
        expand(f"{DATA_DIR}/{{session_run}}/{{parcellation}}/{{session_run}}/data.h5", session_run = session_runs,  parcellation = parcellations), #TODO add all session_run = session_runs+["All"]
        #Plot of parcellations
        expand(f"{DATA_DIR}/{{session_run}}/{{parcellation}}/visualization/combined_parcels.pdf", session_run = session_runs,  parcellation = parcellations)

rule conditions:
    input:
        expand([f"{DATA_DIR}/{dataset_id}/{{parcellation}}/{subset_id}/Features/{{cond}}/data.h5"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
                parcellation = parcellations, cond=aggr_conditions)

rule condition_diffs:
    input:
        expand([f"{PLOTS_DIR}/{dataset_id}/{subset_id}/{'.'.join(trial_conditions)}/b-maps/{{parcellation}}/all_cond_difference_b-maps.pdf"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
                parcellation = parcellations)

rule feature:
    input:
        expand([f"{DATA_DIR}/{dataset_id}/{{parcellation}}/{subset_id}/Features/{{trial_conditions}}/{{feature}}/{{trial_conditions}}.{{feature}}.{config['export_type']}"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
                parcellation = parcellations, trial_conditions = trial_conditions, feature =  features)
    output:
        dict = f"results/exports/feats_hash{hash_config(config)}.{config['export_type']}"
    params:
        iter = [session_runs, getKeys(parcellations), getKeys(trial_conditions), getKeys(features)],
        reorder = "feature" #TODO can you access rule name from script context?
    log:
        f"{EXPORTS_DIR}/feats_hash{hash_config(config)}.log"

    conda:
        "envs/environment.yaml"
    script:
        "scripts/aggregate_dict.py"


rule decode:
    input:
        #Decoding performance across: features, parcellation and both
        expand([f"{PLOTS_DIR}/{dataset_id}/{subset_id}/{'.'.join(aggr_conditions)}/{{parcellation}}_perf.pdf"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
                    parcellation = parcellations, ),
        expand([f"{PLOTS_DIR}/{dataset_id}/{subset_id}/{'.'.join(aggr_conditions)}/{{feature}}_perf.pdf"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
                    feature =  features, ),
        expand([f"{PLOTS_DIR}/{dataset_id}/{subset_id}/{'.'.join(aggr_conditions)}/all_perf.pdf"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids], ),

        #Plot Train/Test across time: on the same timepoints, on different timepoint
        expand([f"{PLOTS_DIR}/{dataset_id}/{subset_id}/{'.'.join(aggr_conditions)}/{{feature}}/{{parcellation}}/performance_over_time.pdf"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
                    parcellation = parcellations, feature =  features, ),
        expand([f"{PLOTS_DIR}/{dataset_id}/{subset_id}/{'.'.join(aggr_conditions)}/{{feature}}/{{parcellation}}/{{decoder}}/performance_matrix.pdf"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
                    parcellation = parcellations, feature =  features, decoder=decoders,),
        
        #Decoding performance over time across: parcellations, features
        expand([f"{PLOTS_DIR}/{dataset_id}/{subset_id}/{'.'.join(aggr_conditions)}/{{feature}}_performance_over_time.pdf"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
                    feature =  features, ),
        expand([f"{PLOTS_DIR}/{dataset_id}/{subset_id}/{'.'.join(aggr_conditions)}/{{parcellation}}_performance_over_time.pdf"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
                    parcellation = parcellations, ),
        
        #Confusion Matrix
        expand([f"{PLOTS_DIR}/{dataset_id}/{subset_id}/{'.'.join(aggr_conditions)}/{{feature}}/{{parcellation}}/{{decoder}}/confusion_matrix.pdf"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
                    parcellation = parcellations, feature =  features, decoder=decoders, ),
        
        #Plot coefs
        #expand([f"{PLOTS_DIR}/{dataset_id}/{subset_id}/{'.'.join(aggr_conditions)}/{{feature}}/{{parcellation}}/{{decoder}}/model_coef_mean.pdf"
        #                for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
        #            parcellation = parcellations, feature =  features, decoder=decoders, ),

        #Plot clustered coefs
        #expand([f"{PLOTS_DIR}/{dataset_id}/{subset_id}/{'.'.join(aggr_conditions)}/{{feature}}/{{parcellation}}/{{decoder}}/CoefsAcrossTime_clustered.pdf"
        #                for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
        #            parcellation = parcellations, feature =  features, decoder=decoders, ),

        #Create models from clusters and test over time
        #expand([f"{PLOTS_DIR}/{dataset_id}/{subset_id}/{'.'.join(aggr_conditions)}/{{feature}}/{{parcellation}}/{{decoder}}/ClusturedModels_perf.pdf"
        #                for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
        #            parcellation = parcellations, feature =  features, decoder=decoders, ),


        ## Plot from df across aggregated datasets
        #expand(f"{PLOTS_DIR}/{'.'.join(aggr_conditions)}/{{feature}}/{{parcellation}}/{{decoder}}/perf_all.datasets.pdf", parcellation = parcellations, feature =  features, decoder=decoders),

rule decode_generalized:
    input:
        expand([f"{PLOTS_DIR}/{dataset_id}/{generalization['decoding_set_id']}_on_{generalization['testing_set_id']}/{'.'.join(aggr_conditions)}/{{feature}}/{{parcellation}}/{{decoder}}/ClusturedModels_perf.pdf"
                        for dataset_id, generalizations in generalize.items() for generalization in generalizations],
                    parcellation = parcellations, feature =  features, decoder=decoders),
        expand([f"{DATA_DIR}/{dataset_id}/{{parcellation}}/{generalization['testing_set_id']}/Decoding/decoder/{'.'.join(aggr_conditions)}/{{feature}}/{{decoder}}/model_from/{generalization['decoding_set_id']}/cluster_perf.pkl"
                        for dataset_id, generalizations in generalize.items() for generalization in generalizations],
                    parcellation = parcellations, feature =  features, decoder=decoders),

rule aggregated_decoding_plots:
    input:
        expand([f"{PLOTS_DIR}/{dataset_id}/{'.'.join(aggr_conditions)}/{{feature}}/{{parcellation}}/{{decoder}}/perf_subset_space_comp.pdf"
                for dataset_id in session_runs.keys() if dataset_id in datasets],
                parcellation = parcellations, feature =  features, decoder=decoders, ),
        #expand([f"{PLOTS_DIR}/{dataset_id}/{'.'.join(aggr_conditions)}/{{feature}}/{{parcellation}}/{{decoder}}/perf_all_space_comp.pdf"
                #for dataset_id in [dataset_aliases["All"]] if unified_space == "Both" ],
                #parcellation = parcellations, feature =  features, decoder=decoders, ),


rule load:
    input:
        expand(f"{DATA_DIR}/{{session_run}}/SVD/{{session_run}}/data.h5",session_run=session_runs)

rule biomarkers:
    input:
        expand([f"{DATA_DIR}/{dataset_id}/{{parcellation}}/{subset_id}/Decoding/rfe/{'.'.join(aggr_conditions)}/{{rfe_n}}/{{feature}}/circle_plot.pdf"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
                    parcellation = parcellations, feature = features, rfe_n = rfe_ns)


rule exports:
    input:
        expand([*[f"{EXPORTS_DIR}/{alias(dataset_id)}/{alias(subset_id)}/{{parcellation}}/temporals.{config['export_type']}"
                        for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
                *[f"{EXPORTS_DIR}/{alias(dataset_id)}/{alias(dataset_id)}/{{parcellation}}/spatials.{config['export_type']}"
                        for dataset_id in session_runs.keys()]],
                    parcellation = parcellations, ),
        #expand([f"{EXPORTS_DIR}/{alias(dataset_id)}/{alias(subset_id)}/{{parcellation}}/{{condition}}/temporals.{config['export_type']}"
        #                for dataset_id, subset_ids in session_runs.items() for subset_id in subset_ids],
        #            parcellation = parcellations, condition=aggr_conditions),




module loading:
    snakefile: "rules/loading.smk"
    config:  config | config['loading']

use rule * from loading

module processing:
    snakefile: "rules/processing.smk"
    config: config | config['processing']

use rule * from processing

module aggregation:
    snakefile: "rules/aggregation.smk"
    config: config | config['aggregation']

use rule * from aggregation

module plotting:
    snakefile: "rules/plotting.smk"
    config: config | config['plotting']

use rule * from plotting

module export:
    snakefile: "rules/export.smk"
    config: config | config['export']

use rule * from export
