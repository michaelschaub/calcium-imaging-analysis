include: "tools/Snakefile.smk"

report: "report/workflow.rst"

ruleorder:  load_GN > load_mSM  > locaNMF > parcellate > feature_concat > thresholding > feature_calculation

from snakemake_tools import getKeys, hash_config

###   Output accumulation rules   ###

#rule subdivided_svd:

#rule brain_alignment:


rule test:
	input:
		expand(f"results/{{session_run}}/{{parcellation}}/{{trials}}/Decoding/decoder/{'.'.join(trial_conditions)}/performances.png", session_run = session_runs+["All"],  parcellation = parcellations, trials= selected_trials),
		expand(f"results/plots/{{session_run}}/{{trials}}/Decoding/{'.'.join(trial_conditions)}/{{feature}}/performances.png", session_run = session_runs+["All"],  feature =  features, trials= selected_trials),
		expand(f"results/{{session_run}}/{{parcellation}}/{{trials}}/Decoding/decoder/{'.'.join(trial_conditions)}/{{feature}}/plots/performance_over_time.png", session_run = session_runs+["All"] ,parcellation = parcellations, feature =  features, trials= selected_trials),
		expand(f"results/{{session_run}}/{{parcellation}}/visualization/combined_parcels.png", session_run = session_runs,  parcellation = parcellations),
		expand(f"results/{{session_run}}/{{parcellation}}/data.h5", session_run = session_runs,  parcellation = parcellations) 

rule parcellation: 
	input: 
		#Result of parcellations
		expand(f"results/{{session_run}}/{{parcellation}}/data.h5", session_run = session_runs,  parcellation = parcellations), #TODO add all session_run = session_runs+["All"]
		#Plot of parcellations
		expand(f"results/{{session_run}}/{{parcellation}}/visualization/combined_parcels.png", session_run = session_runs,  parcellation = parcellations)


rule feature:
	input:
		expand(f"results/{{session_run}}/{{parcellation}}/{{trials}}/Features/{{trial_conditions}}/{{feature}}/{{trial_conditions}}.{{feature}}.{config['export_type']}", session_run = session_runs+["All"],  parcellation = parcellations, trials= selected_trials, trial_conditions = trial_conditions, feature =  features)
	output:
		dict = f"results/exports/feats_hash{hash_config(config)}.{config['export_type']}"
	params:
		iter = [session_runs+["All"], getKeys(parcellations), getKeys(selected_trials), getKeys(trial_conditions), getKeys(features)],
		reorder = "feature" #TODO can you access rule name from script context?

	conda:
		"envs/environment.yaml"
	script:
		"scripts/aggregate_dict.py"

rule decode:
	input:
		#Decoding performance accuracy across features
		expand(f"results/{{session_run}}/{{parcellation}}/{{trials}}/Decoding/decoder/{'.'.join(trial_conditions)}/performances.png", session_run = session_runs+["All"],  parcellation = parcellations, trials= selected_trials),
		#Decoding performance across parcellation 
		expand(f"results/plots/{{session_run}}/{{trials}}/Decoding/{'.'.join(trial_conditions)}/{{feature}}/performances.png", session_run = session_runs+["All"],  feature =  features, trials= selected_trials),
		#Plot Train/Test across Time (on the same timepoints)
		expand(f"results/{{session_run}}/{{parcellation}}/{{trials}}/Decoding/decoder/{'.'.join(trial_conditions)}/{{feature}}/plots/performance_over_time.png", session_run = session_runs+["All"] ,parcellation = parcellations, feature =  features, trials= selected_trials),
		#Plot Train/Test on different Timepoints
		expand(f"results/{{session_run}}/{{parcellation}}/{{trials}}/Decoding/decoder/{'.'.join(trial_conditions)}/{{feature}}/plots/{{decoder}}_performance_matrix.png", session_run = session_runs+["All"] ,parcellation = parcellations, feature =  features, trials= selected_trials, decoder=decoders)

rule load:
	input:
		expand("results/{session_run}/SVD/data.h5",session_run=session_runs)

rule biomarkers:
	input:
		expand(f"results/{{session_run}}/{{parcellation}}/{{trials}}/Decoding/rfe/{'.'.join(trial_conditions)}/{{rfe_n}}/{{feature}}/circle_plot.png", session_run = session_runs, parcellation = parcellations, trials = selected_trials, feature = features, rfe_n = rfe_ns)






# The first rule is default
rule decoding_performances:
	input:
		[ f"results/{config['output']['processed_dates']}/{parcellation}/{trials}/Decoding/decoder/{'.'.join(trial_conditions)}/performances.png"
			for parcellation in parcellations
			for trials in selected_trials],
		#[ f"results/{'_'.join(subject_dates)}/{parcellation}/{trials}/Decoding/decoder/{'.'.join(trial_conditions)}/{feature}/plots/performance.png"
		#	for parcellation in parcellations
		#	for trials in selected_trials
		#	for feature in features],
		[ f"results/plots/{config['output']['processed_dates']}/{trials}/Decoding/{'.'.join(trial_conditions)}/{feature}/performances.png"
		  	for feature in features
		   	for trials in selected_trials],
	output:
		decoders = [ f"results/runs/{run_id}/features_{parcellation}_{trials}_{config['output']['processed_dates']}_{'.'.join(trial_conditions)}_decoding_performances.png"
			for parcellation in parcellations
			for trials in selected_trials],
		#decoder = [ f"results/runs/{run_id}/Features/{'_'.join(subject_dates)}_{parcellation}_{trials}_{'.'.join(trial_conditions)}_{feature}_performance.png"
		#	for parcellation in parcellations
		#	for trials in selected_trials
		#	for feature in features],
		parcellations = [ f"results/runs/{run_id}/parcellations_{feature}_{trials}_{config['output']['processed_dates']}_{'.'.join(trial_conditions)}_decoding_performances.png"
			for feature in features
			for trials in selected_trials],
	log:
		f"results/runs/{run_id}/pipeline_entry.log"
	conda:
		"envs/environment.yaml"
	resources:
		mem_mb=lambda wildcards, attempt: mem_res(wildcards,attempt,4000,1000)
	script:
		"scripts/run_aggregation.py"


module loading:
	snakefile: "rules/loading.smk"
	config:  config | config['loading']

use rule * from loading

module processing:
	snakefile: "rules/processing.smk"
	config: config | config['processing']

use rule * from processing

module plotting:
	snakefile: "rules/plotting.smk"
	config: config | config['plotting']

use rule * from plotting
